{
    "model": "chatglm2-6b-torch-fp16",
    "model_path": "byte_mlperf/model_zoo/sota/chatglm2-6b",
    "framework": "Pytorch",
    "framework_version": "1.13.1",
    "model_format": "bin",
    "model_precision": "FP16",
    "inputs": null,
    "outputs": null,
    "input_shape": null,
    "input_type": null,
    "dataset_name": null,
    "max_batch_size": null,
    "is_quantized": false
}