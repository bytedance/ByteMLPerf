/*************************************************************************
 * Copyright (C) [2019-2023] by Cambricon, Inc.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *************************************************************************/
#include <float.h>
#include <math.h>
#include <iostream>
#include <unordered_map>
#include <map>
#include <vector>
#include <algorithm>
#include <cstring>
#include <string>

#include "cnrt.h"
#include "cn_api.h"
#include "kernels.h"

// CHECK with a error if condition is not true.
#define CHECK(condition, ...)                                                       \
    if (!(condition)) {                                                             \
        std::cout << " Check failed: " #condition "." #__VA_ARGS__ << std::endl;    \
        exit(-1);                                                                   \
    }


class DataType {
 public:
  /// all datatype in library
  enum Type {
    INVALID,
    INT8,
    HALF,
    BFLOAT16,
    FLOAT,
  };
  explicit DataType(std::string dtype = "") {
    std::unordered_map<std::string, Type> parse_typestr = {
      {"int8", INT8}, {"INT8", INT8},
      {"half", HALF}, {"HALF", HALF},
      {"bfloat16", BFLOAT16}, {"BFLOAT16", BFLOAT16},
      {"float", FLOAT}, {"FLOAT", FLOAT},
    };
    if (parse_typestr.find(dtype) != parse_typestr.end()) {
      type_ = parse_typestr.at(dtype);
    } else {
      type_ = INVALID;
    }
  }
  Type type() const noexcept { return type_; }
  bool operator ==(const DataType& other) const {
    return type() == other.type();
  }

  bool operator !=(const DataType& other) const {
    return type() != other.type();
  }

  bool isFloatPoint() const {
    switch (type_) {
      case HALF:
      case BFLOAT16:
      case FLOAT:
        return true;
      case INT8:
      default:
        return false;
    }
  }

  std::string to_string() const {
    switch (type_) {
      case INT8: return "INT8";
      case HALF: return "HALF";
      case BFLOAT16: return "BF16";
      case FLOAT: return "FLOAT";
      case INVALID: return "INVALID TYPE";
    }
    return "INVALID TYPE";
  }

 private:
  Type type_;
};





struct DeviceInfo {
public:
    DeviceInfo() = default;
    float frequency;
    int queue_num;
    float algorithm_value;
};

class InputParam {
 public:
    InputParam() = default;

    InputParam(int argc, char* argv[]) {
        std::string conv_type;
        for (int i = 1; i < argc; ++i) {
            std::string arg(argv[i]);
            if (arg == "--single") {
                single_core_ = true;
            } else if (arg == "--task") {
                if (++i != argc) {
                    task_name_ = argv[i];
                }
            }
        }
        selectKernel();
    }

    void selectKernel() {
        auto search = kernel_mapping.find(this->task_name_);
        if (search != kernel_mapping.end()) {
            this->kernel_ = kernel_mapping.at(this->task_name_);
        }
    }


    bool single_core_ = false;
    std::string task_name_ = ""; 
    void (* kernel_)(PeakTimeInfo *peak_ptr) = nullptr;


private:
    static std::unordered_map<std::string, void (*)(PeakTimeInfo *peak_ptr)> kernel_mapping;
};


// kernel function mapping
std::unordered_map<std::string, void (*)(PeakTimeInfo *peak_ptr)> InputParam::kernel_mapping = {
    // dst = src0 * scalar1 + scalar2
    {"fma_float32", fma_float32}, 
    {"fma_float16", fma_float16}, 
    {"fma_bfloat16", fma_bfloat16}, 
    {"fma_int8", fma_int8}, 

    // pow2
    {"pow2_float32", pow2_float32}, 
    {"pow2_bfloat16", pow2_bfloat16}
};






// device_name, frequency, queue_num, algo, theory_compute_capablity
std::map<std::string, DeviceInfo> kDeviceInfoTable = {
    {"MLU580-X4", {1.25f, 1, 1.024f}},
    {"MLU590-M9DK", {1.85f, 1, 1.024f}},
};


typedef struct peakParamsBuffer_s {
    PeakTimeInfo *peak_ptr;
    float theory_compute_capablity;
} *peakParamsBuffer_t;


class Device {
public:
    explicit Device(InputParam input_param) : input_param_(input_param) {}

    void initDevice() {
        // runtime init
        initMluCardModelParam();
        for (int i = 0; i < queue_num_; ++i) {
            cnrtQueue_t rt_queue;
            CNRT_CHECK(cnrtSetDevice(i));
            CNRT_CHECK(cnrtQueueCreate(&rt_queue));
            queue_vec_.push_back(rt_queue);
        }
    }

  void initMluCardModelParam() {
        CNdev mlu_dev;
        CHECK(CN_SUCCESS == cnInit(0));
        CHECK(CN_SUCCESS == cnDeviceGet(&mlu_dev, 0));
        char tmp_name_[100];
        CHECK(CN_SUCCESS == cnDeviceGetName(tmp_name_, 100, mlu_dev));
        device_name_ = tmp_name_;
        int pos = device_name_.find('[');
        device_name_ = device_name_.substr(0, pos);
        for (const auto& info_pair : kDeviceInfoTable) {
            std::string name = info_pair.first;
            if (strncmp(name.c_str(), device_name_.c_str(), name.size()) == 0) {
            device_name_ = name;
            break;
            }
        }
        queue_num_ = kDeviceInfoTable[device_name_].queue_num;
    }



    void initDeviceParam() {
        // get device info
        CNdev mlu_dev;
        CHECK(CN_SUCCESS == cnCtxGetDevice(&mlu_dev));
        CHECK(CN_SUCCESS == cnDeviceGetAttribute(&cluster_num_,
            CN_DEVICE_ATTRIBUTE_MAX_CLUSTER_COUNT, mlu_dev));
        CHECK(CN_SUCCESS == cnDeviceGetAttribute(&core_num_per_cluster_,
            CN_DEVICE_ATTRIBUTE_MAX_CORE_COUNT_PER_CLUSTER, mlu_dev));
        task_num_ = cluster_num_ * core_num_per_cluster_;
    }


    void initLaunchParam() {
        func_type_ = CNRT_FUNC_TYPE_UNION1;
        dim_.x = core_num_per_cluster_;
        dim_.y = cluster_num_;
        dim_.z = 1;
        if (input_param_.single_core_) {
            dim_.x = 1;
            dim_.y = 1;
            func_type_ = CNRT_FUNC_TYPE_BLOCK;
        }
    }

    void initWorkspace() {
    for (int i = 0; i < queue_num_; ++i) {
        CNRT_CHECK(cnrtSetDevice(i));
        // init ptr
        int malloc_size = task_num_ * sizeof(PeakTimeInfo);
        PeakTimeInfo *peak_ptr_device;
        peakParamsBuffer_t params = nullptr;
        CNRT_CHECK(cnrtMalloc((void **)(&peak_ptr_device), malloc_size));
        PeakTimeInfo *peak_ptr_host(new PeakTimeInfo[task_num_]);
        // set kernel param
        params = (peakParamsBuffer_t)malloc(sizeof(struct peakParamsBuffer_s));
        params->peak_ptr = peak_ptr_device;
        params->theory_compute_capablity = theory_compute_capablity_;
        // push back param
        device_ptr_vec_.push_back(peak_ptr_device);
        host_ptr_vec_.push_back(peak_ptr_host);
        params_vec_.push_back(params);
    }
    }

    void launchKernel() {
        for (int i = 0; i < queue_num_; ++i) {
            CNRT_CHECK(cnrtSetDevice(i));
            int malloc_size = task_num_ * sizeof(PeakTimeInfo);
            input_param_.kernel_<<<dim_, func_type_, queue_vec_[i]>>>(params_vec_[i]->peak_ptr);
            CNRT_CHECK(cnrtQueueSync(queue_vec_[i]));
            CNRT_CHECK(cnrtMemcpy(host_ptr_vec_[i], device_ptr_vec_[i], malloc_size, CNRT_MEM_TRANS_DIR_DEV2HOST));
        }
    }

  void freeParam() {
    for (int i = 0; i < queue_num_; ++i) {
      CNRT_CHECK(cnrtQueueDestroy(queue_vec_[i]));
      free(params_vec_[i]);
      CNRT_CHECK(cnrtFree(device_ptr_vec_[i]));
      delete host_ptr_vec_[i];
    }
  }

  // input param
  InputParam input_param_;

  // runtime param
  std::vector<cnrtQueue_t> queue_vec_;

  // device param
  int cluster_num_ = 0;
  int core_num_per_cluster_ = 0;
  float theory_compute_capablity_ = 0;
  int task_num_ = 0;
  std::string device_name_;
  int queue_num_;
  // launch param
  cnrtDim3_t dim_;
  cnrtFunctionType_t func_type_;
  // workspace param
  std::vector<peakParamsBuffer_t> params_vec_;
  std::vector<PeakTimeInfo *> device_ptr_vec_;
  std::vector<PeakTimeInfo *> host_ptr_vec_;
};


void printDeviceInfo(
    const InputParam& input_param,
    const Device& device
) {
    std::string ops = "TFLOPS";
    float fusion_hardware_time = 0;
    float fusion_tflops = 0;
    // float compute_capablity_theory = 0;
    for (int queue_index = 0; queue_index < device.queue_num_; ++queue_index) {
    int temp_fusion = 0;
    for (int task_Id = 0; task_Id < device.task_num_; ++task_Id) {
        if(static_cast<float>(device.host_ptr_vec_[queue_index][task_Id].fusion_hardware_time) > fusion_hardware_time){
        temp_fusion = task_Id;
        }
    }

    // for (int task_Id = 0; task_Id < device.task_num_; ++task_Id) {
        fusion_hardware_time = std::max(fusion_hardware_time,
        static_cast<float>(device.host_ptr_vec_[queue_index][temp_fusion].fusion_hardware_time));
        fusion_tflops = std::max(fusion_tflops,
        static_cast<float>(device.host_ptr_vec_[queue_index][temp_fusion].fusion_tflops));
    // }
    }

    std::string func_type = device.func_type_ == CNRT_FUNC_TYPE_UNION1 ? "CNRT_FUNC_TYPE_UNION1" : "CNRT_FUNC_TYPE_BLOCK";
    printf(">>>>>>>>>> Kernel Info: <<<<<<<<<<\n");
    printf("kernel run iterations = 1000\n");
    printf("task_dim = (%d, %d, %d), task_type = %s, queue_num = %d\n",
    device.dim_.x, device.dim_.y, device.dim_.z, func_type.c_str(), device.queue_num_);
    printf("\n");
    printf(">>>>>>>>>> computing power data:\n");
    printf("Fusion instruction HardWare time: %.2f us, correspond to %.2f TOPS;\n",
    fusion_hardware_time, fusion_tflops);
    printf("\n");
}




int main(int argc, char* argv[]) {
    InputParam input_param(argc, argv);

    Device device(input_param);
    device.initDevice();
    device.initDeviceParam();
    device.initLaunchParam();
    device.initWorkspace();

    std::cout << std::endl;
    std::cout << "device num: " << device.device_name_ << std::endl;
    std::cout << "cluster num: " << device.cluster_num_ << std::endl;

    std::cout << "core num per cluster: " << device.core_num_per_cluster_ << std::endl;
    std::cout << "task num: " << device.task_num_ << std::endl;
    std::cout << std::endl;

    device.launchKernel();
    printDeviceInfo(input_param, device);
    device.freeParam();
    return 0;
}
